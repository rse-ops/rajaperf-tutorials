{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2018c0c-1dbc-4a5d-9d22-62b3bf4f40d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adding a kernel to RAJAPerf \n",
    "\n",
    "In this section we will be adding a simple kernel to RAJAPerf, into a new group called tutorial with kernel name Tutorial_KERNEL. \n",
    "The tutorial uses several skeletal files for sequential and openmp, base and RAJA variants.\n",
    "The bulk of this notebook is to populate these skeletal files.\n",
    "\n",
    "We will compile and run them using the same charting techniques we demonstrated earlier in a subsequent notebook.\n",
    "\n",
    "[Back to Table of Contents](./00-intro-and-contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78ec08-d685-46a6-9725-2c98447fc73c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Always run the following cell to init/reinit notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b21b7-c0dd-4f19-ac59-3e2445250d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pragma cling add_include_path(\"/opt/conda/include/\")\n",
    "#pragma cling add_library_path(\"/opt/conda/lib/\")\n",
    "#pragma cling load(\"libomp\")\n",
    "\n",
    "#pragma cling add_include_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/camp-2022.03.2-nh5kkatqzxgiwxusi4ddpyhf2zcqxyow/include/\")\n",
    "#pragma cling add_include_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/raja-2022.03.0-f7p4trkfeq4gcmqnt5623haejgcvwlvl/include/\")\n",
    "#pragma cling add_library_path(\"/home/jovyan/spack/opt/spack/linux-ubuntu22.04-x86_64/gcc-10.4.0/raja-2022.03.0-f7p4trkfeq4gcmqnt5623haejgcvwlvl/lib/\")\n",
    "#pragma cling load(\"libRAJA\")\n",
    "\n",
    "#pragma cling add_include_path(\"/home/jovyan/code/RAJAPerf/build_gcc/include/\")\n",
    "#pragma cling add_include_path(\"/home/jovyan/code/RAJAPerf/src/\")\n",
    "#pragma cling add_library_path(\"/home/jovyan/code/RAJAPerf/build_gcc/lib/\")\n",
    "#pragma cling load(\"libcommon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9df9fb-a868-4e43-a4ee-a99db6f9d16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introducing Polybench Covariance kernel as our surrogate\n",
    "\n",
    "Using version 4 of the kernel\n",
    "```\n",
    "static\n",
    "void kernel_covariance(int m, int n,\n",
    "\t\t       DATA_TYPE float_n,\n",
    "\t\t       DATA_TYPE POLYBENCH_2D(data,M,N,m,n),\n",
    "\t\t       DATA_TYPE POLYBENCH_2D(symmat,M,M,m,m),\n",
    "\t\t       DATA_TYPE POLYBENCH_1D(mean,M,m))\n",
    "{\n",
    "  int i, j, k;\n",
    "#pragma scop\n",
    "  for (j = 0; j < _PB_M; j++)\n",
    "    {\n",
    "      mean[j] = SCALAR_VAL(0.0);\n",
    "      for (i = 0; i < _PB_N; i++)\n",
    "        mean[j] += data[i][j];\n",
    "      mean[j] /= float_n;\n",
    "    }\n",
    "\n",
    "  for (i = 0; i < _PB_N; i++)\n",
    "    for (j = 0; j < _PB_M; j++)\n",
    "      data[i][j] -= mean[j];\n",
    "\n",
    "  for (i = 0; i < _PB_M; i++)\n",
    "    for (j = i; j < _PB_M; j++)\n",
    "      {\n",
    "        cov[i][j] = SCALAR_VAL(0.0);\n",
    "        for (k = 0; k < _PB_N; k++)\n",
    "\t  cov[i][j] += data[k][i] * data[k][j];\n",
    "        cov[i][j] /= (float_n - SCALAR_VAL(1.0));\n",
    "        cov[j][i] = cov[i][j];\n",
    "      }\n",
    "#pragma endscop\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52a28e-87e6-4e08-aef0-15aa11b3f973",
   "metadata": {},
   "source": [
    "## create macros for loop bodies\n",
    "We'll use relative indexing for the non-RAJA variants, since we're using Real_ptr vs actual Matrices.\n",
    "\n",
    "For consistency we'll use i,j,k = M,N,M index spaces in all the variants below\n",
    "\n",
    "For the RAJA variants we'll use RAJA Views\n",
    "\n",
    "Note for the last loop body, the inner for loop is dependent on the outer loop index.\n",
    "So, most of the symmat calculation is put into a loop body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ad794-7406-4edc-be33-33fc7dc23365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define POLYBENCH_VAR_BODY0 \\\n",
    "  mean[i] = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1 \\\n",
    "  mean[i] += ldata[(j*m)+i];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2 \\\n",
    "  mean[i] /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3 \\\n",
    "  ldata[(j*m)+i] -= mean[i];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4 \\\n",
    "  for(int kk = i; kk < m; kk++) { \\\n",
    "    symmat[(i*m)+kk] = 0.0; \\\n",
    "    for(int jj = 0; jj < n; jj++) { \\\n",
    "      symmat[(i*m)+kk] += ldata[(jj*m)+i] * ldata[(jj*m)+kk]; \\\n",
    "    } \\\n",
    "    symmat[(i*m)+kk] /= (float_n - 1.0); \\\n",
    "    symmat[(kk*m)+i] = symmat[(i*m)+kk]; \\\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53275e2-2788-49f6-8471-f4cef13f5f92",
   "metadata": {},
   "source": [
    "## setup RAJA views and RAJA lambda bodies in terms of the RAJA views\n",
    "The cell below illustrates how to setup a view with a simple 2D layout type\n",
    "Note that the rightmost index j in our example is fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb5083-6e36-4fea-bb4e-d8acdf439599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "int L=2;\n",
    "\n",
    "double* A = new double [L * L];\n",
    "\n",
    "RAJA::View<double,RAJA::Layout<2> > Aview(A, L, L);\n",
    "Aview(0,0) = 0.0;\n",
    "Aview(0,1) = 1.0;\n",
    "Aview(1,0) = 2.0;\n",
    "Aview(1,1) = 3.0;\n",
    "for(int i = 0; i < L; ++i) {\n",
    "    for(int j = 0; j < L; ++j) {\n",
    "      printf(\"%p \",&Aview(i,j));\n",
    "    }\n",
    "}\n",
    "\n",
    "delete[] A;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d61085-7b85-4d72-aa93-ca7fea4b8c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "\n",
    "#define POLYBENCH_VAR_VIEWS_RAJA \\\n",
    "  using VIEW_1 = RAJA::View<Real_type, RAJA::Layout<1> >; \\\n",
    "  using VIEW_2 = RAJA::View<Real_type, RAJA::Layout<2> >; \\\n",
    "  VIEW_1 meanview(mean,m); \\\n",
    "  VIEW_2 dataview(ldata,n,m); \\\n",
    "  VIEW_2 symmatview(symmat,m,m);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY0_RAJA \\\n",
    "  meanview(i) = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1_RAJA \\\n",
    "  meanview(i) += dataview(j,i);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2_RAJA \\\n",
    "  meanview(i) /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3_RAJA \\\n",
    "  dataview(j,i) -= meanview(i);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4_RAJA \\\n",
    "  for(Index_type kk=i; kk < m; kk++) { \\\n",
    "    symmatview(i,kk) = 0.0; \\\n",
    "    for(Index_type jj=0; jj<n; jj++) { \\\n",
    "      symmatview(i,kk) += dataview(jj,i) * dataview(jj,kk); \\\n",
    "    } \\\n",
    "    symmatview(i,kk) /= (float_n - 1.0); \\\n",
    "    symmatview(kk,i) = symmatview(i,kk); \\\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec0328-742e-475b-a7a6-9498bc26e9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "\n",
    "const int M = 2;\n",
    "const int N = 4;\n",
    "//rajaperf::Real_ptr g_data = (rajaperf::Real_ptr)rajaperf::detail::allocHostData(N*M, RAJA::DATA_ALIGN);\n",
    "//rajaperf::Real_ptr g_mean = (rajaperf::Real_ptr)rajaperf::detail::allocHostData(M, RAJA::DATA_ALIGN);\n",
    "//rajaperf::Real_ptr g_symmat = (rajaperf::Real_ptr)rajaperf::detail::allocHostData(M*M, RAJA::DATA_ALIGN);\n",
    "rajaperf::Real_ptr g_data = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "rajaperf::Real_ptr g_mean = (rajaperf::Real_ptr)malloc(M*sizeof(rajaperf::Real_ptr));\n",
    "rajaperf::Real_ptr g_symmat = (rajaperf::Real_ptr)malloc(M*M*sizeof(rajaperf::Real_ptr));\n",
    "rajaperf::detail::resetDataInitCount();\n",
    "rajaperf::detail::initDataRandSign(g_data,N*M);\n",
    "rajaperf::detail::initDataConst(g_mean,M,0.0);\n",
    "rajaperf::detail::initDataConst(g_symmat,M*M,0.0);\n",
    "for(int i=0;i<M;i++) printf(\"%lf \",g_mean[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34a8f1-bab5-4075-ada3-b0ff9f6f7d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "// let's create a pure sequential kernel for now to check what the output looks like\n",
    "// Note by default we create 1d index spaces but later we'll setup RAJA views to index 2d\n",
    "void kernel_cov(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "  int i, j, k;\n",
    "\n",
    "  int _PB_M = m;\n",
    "  int _PB_N = n;\n",
    "  double float_n = n;\n",
    "  \n",
    "  rajaperf::Real_ptr ldata = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*n*m);\n",
    "    \n",
    "  /* Determine mean of column vectors of input data matrix */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "        POLYBENCH_VAR_BODY1; \n",
    "      }\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "  }\n",
    "\n",
    "  /* Center the column vectors. */\n",
    "  for (j = 0; j < _PB_N; j++) {\n",
    "    for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Calculate the m * m covariance matrix. */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "    POLYBENCH_VAR_BODY4;\n",
    "  }\n",
    "    \n",
    "  printf(\"Done with kernel\\n\");\n",
    "    \n",
    "  free(ldata);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106075f-67ec-4329-80dc-6c2acd780b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::detail::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::detail::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::detail::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f284a-5846-4eba-a0a7-dce70e57baab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## setup lamdba seq to make it easier to code up the RAJA seq variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4779b8c9-7234-4525-851b-0cd75f8dd4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_lambda(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "    int i, j, k;\n",
    "    rajaperf::Real_ptr ldata = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "    std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m*n);\n",
    "    double float_n = n;\n",
    "    \n",
    "    using Index_type = RAJA::Index_type;\n",
    "    using Real_type = RAJA::Real_type;\n",
    "    \n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY1;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY4;\n",
    "    };\n",
    "\n",
    "    for(Index_type i = 0; i < m; ++i) {\n",
    "        poly_var_base_lam0(i);\n",
    "        for(Index_type j = 0; j < n; ++j) {\n",
    "            poly_var_base_lam1(i,j);\n",
    "        }\n",
    "        poly_var_base_lam2(i);\n",
    "    }\n",
    "    \n",
    "    for(Index_type j = 0; j < n; ++j) {\n",
    "        for(Index_type i = 0; i < m; ++i) {\n",
    "            poly_var_base_lam3(i,j);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for(Index_type i = 0; i < m; ++i) {\n",
    "        poly_var_base_lam4(i);\n",
    "    }\n",
    "              \n",
    "    free(ldata);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1daa7c3-7389-4035-ab4b-27c7e19a5a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_lambda(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::detail::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::detail::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::detail::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51777b7c-c298-4114-a100-a9eb924085a2",
   "metadata": {},
   "source": [
    "## setup a RAJA Seq function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2d852-4b0d-4c41-99de-684c6d786dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//%%file raja_seq_cov.txt\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_raja(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "    using Index_type = RAJA::Index_type;\n",
    "    using Real_type = RAJA::Real_type;\n",
    "    //Index_type i,j,k;\n",
    "    rajaperf::Real_ptr ldata = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "    std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m*n);\n",
    "\n",
    "    double float_n = n;\n",
    "    \n",
    "    POLYBENCH_VAR_VIEWS_RAJA;\n",
    "    \n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY0_RAJA; \n",
    "    };\n",
    "    \n",
    "   auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY1_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY2_RAJA; \n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY3_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY4_RAJA;\n",
    "    };\n",
    "\n",
    "     using EXECPOL = RAJA::KernelPolicy<\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec,    // over m\n",
    "                          RAJA::statement::Lambda<0, RAJA::Segs<0> >,  // i\n",
    "                          RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                            RAJA::statement::Lambda<1, RAJA::Segs<0,1> > // i,j\n",
    "                          >,\n",
    "                          RAJA::statement::Lambda<2, RAJA::Segs<0> > // i\n",
    "                        >,\n",
    "                        RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                          RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                            RAJA::statement::Lambda<3, RAJA::Segs<0,1> > // i,j\n",
    "                          >\n",
    "                        >,\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                          RAJA::statement::Lambda<4, RAJA::Segs<0> >\n",
    "                        >\n",
    "                      >;  \n",
    " \n",
    "   RAJA::kernel_param<EXECPOL>(\n",
    "          RAJA::make_tuple(RAJA::RangeSegment{0,m}, RAJA::RangeSegment{0,n}),\n",
    "          RAJA::tuple<double>{0.0}, // we're using kernel_param for the convenience of specifying iteration spaces (Segs), so we need this param tuple\n",
    "          poly_var_base_lam0,\n",
    "          poly_var_base_lam1,\n",
    "          poly_var_base_lam2,\n",
    "          poly_var_base_lam3,\n",
    "          poly_var_base_lam4\n",
    "        );\n",
    " \n",
    "  free(ldata);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43797b88-e7d5-4ed5-923c-53d6446ce82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_raja(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::detail::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::detail::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::detail::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80e0dd-06b4-4cbe-87f6-de7add7e1187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_openmp(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "  int i, j, k;\n",
    "\n",
    "  int _PB_M = m;\n",
    "  int _PB_N = n;\n",
    "  double float_n = n;\n",
    "  \n",
    "  rajaperf::Real_ptr ldata = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*n*m);\n",
    "    \n",
    "  /* Determine mean of column vectors of input data matrix */\n",
    "  #pragma omp parallel for\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "        POLYBENCH_VAR_BODY1; \n",
    "      }\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "  }\n",
    "\n",
    "  #pragma omp parallel for collapse(2)\n",
    "  /* Center the column vectors. */\n",
    "  for (j = 0; j < _PB_N; j++) {\n",
    "    for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  #pragma omp parallel for\n",
    "  /* Calculate the m * m covariance matrix. */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "    POLYBENCH_VAR_BODY4;\n",
    "  }\n",
    "    \n",
    "  free(ldata);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f6f521-fc5d-431a-bde0-cccb15417284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_openmp(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::detail::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::detail::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::detail::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab589923-a5b6-4ccc-b745-727cfd1ddac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "//%%file raja_openmp_cov.txt\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "void kernel_cov_raja_openmp(int m, int n, rajaperf::Real_ptr data, rajaperf::Real_ptr mean, rajaperf::Real_ptr symmat)\n",
    "{\n",
    "\n",
    "    using Index_type = RAJA::Index_type;\n",
    "    using Real_type = RAJA::Real_type;\n",
    "    \n",
    "    rajaperf::Real_ptr ldata = (rajaperf::Real_ptr)malloc(N*M*sizeof(rajaperf::Real_ptr));\n",
    "    std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m*n);\n",
    "\n",
    "    double float_n = n;\n",
    "    \n",
    "    POLYBENCH_VAR_VIEWS_RAJA;\n",
    "    \n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY0_RAJA; \n",
    "    };\n",
    "    \n",
    "   auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY1_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY2_RAJA; \n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY3_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY4_RAJA;\n",
    "    };\n",
    "\n",
    "     using EXECPOL = RAJA::KernelPolicy<\n",
    "                        RAJA::statement::For<0, RAJA::omp_parallel_for_exec,    // over m\n",
    "                          RAJA::statement::Lambda<0, RAJA::Segs<0> >,  // i\n",
    "                          RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                            RAJA::statement::Lambda<1, RAJA::Segs<0,1> > // i,j\n",
    "                          >,\n",
    "                          RAJA::statement::Lambda<2, RAJA::Segs<0> > // i\n",
    "                        >,\n",
    "                        RAJA::statement::For<1, RAJA::omp_parallel_for_exec,  // over n\n",
    "                          RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                            RAJA::statement::Lambda<3, RAJA::Segs<0,1> > // i,j\n",
    "                          >\n",
    "                        >,\n",
    "                        RAJA::statement::For<0, RAJA::omp_parallel_for_exec, // over m\n",
    "                          RAJA::statement::Lambda<4, RAJA::Segs<0> >\n",
    "                        >\n",
    "                      >;  \n",
    " \n",
    "   RAJA::kernel_param<EXECPOL>(\n",
    "          RAJA::make_tuple(RAJA::RangeSegment{0,m}, RAJA::RangeSegment{0,n}),\n",
    "          RAJA::tuple<double>{0.0}, // we're using kernel_param for the convenience of specifying iteration spaces (Segs), so we need this param tuple\n",
    "          poly_var_base_lam0,\n",
    "          poly_var_base_lam1,\n",
    "          poly_var_base_lam2,\n",
    "          poly_var_base_lam3,\n",
    "          poly_var_base_lam4\n",
    "        );\n",
    " \n",
    "  free(ldata);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad1f32-3016-4632-9135-835310ead70a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "{\n",
    "  kernel_cov_raja_openmp(M,N,g_data,g_mean,g_symmat);\n",
    "  long double checksum_mean = rajaperf::detail::calcChecksum(g_mean,M,1.0);\n",
    "  long double checksum_symmat = rajaperf::detail::calcChecksum(g_symmat,M*M,1.0);\n",
    "  long double checksum_data = rajaperf::detail::calcChecksum(g_data,N*M,1.0);\n",
    "  printf(\"%8.12Lf\\n\",checksum_mean);\n",
    "  printf(\"%8.12Lf\\n\",checksum_symmat);\n",
    "  printf(\"%8.12Lf\\n\",checksum_data);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901c627-c31d-400f-b297-28041387015a",
   "metadata": {},
   "source": [
    "## Save code segments \n",
    "This next section will save code fragments to files which we will copy/paste into the skeletons via script in the next notebook  \n",
    "\n",
    "We'll use the %%file Jupyter magic which Xeus-cling provides to do this.  \n",
    "\n",
    "Currently, we cannot use both %%file and run the code, so we do the saving in a separate section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c14b3-a93a-4346-a6af-8c040925fbfe",
   "metadata": {},
   "source": [
    "## TUTORIAL_KERNEL.hpp\n",
    "So in the following source, we'll insert these code fragments found in the following cells\n",
    "data_setup.txt\n",
    "loop_bodies.txt\n",
    "class_variables.txt\n",
    "```\n",
    "///\n",
    "/// TUTORIAL_KERNEL kernel reference implementation:\n",
    "///\n",
    "\n",
    "\n",
    "#ifndef RAJAPerf_TUTORIAL_KERNEL_HPP\n",
    "#define RAJAPerf_TUTORIAL_KERNEL_HPP\n",
    "\n",
    "// insert data_setup.txt\n",
    "\n",
    "// insert loop_bodies.txt\n",
    "\n",
    "#include \"common/KernelBase.hpp\"\n",
    "\n",
    "namespace rajaperf\n",
    "{\n",
    "\n",
    "class RunParams;\n",
    "\n",
    "namespace tutorial\n",
    "{\n",
    "\n",
    "class TUTORIAL_KERNEL : public KernelBase\n",
    "{\n",
    "public:\n",
    "\n",
    "  TUTORIAL_KERNEL(const RunParams& params);\n",
    "\n",
    "  ~TUTORIAL_KERNEL();\n",
    "\n",
    "  void setUp(VariantID vid, size_t tune_idx);\n",
    "  void updateChecksum(VariantID vid, size_t tune_idx);\n",
    "  void tearDown(VariantID vid, size_t tune_idx);\n",
    "\n",
    "  void runSeqVariant(VariantID vid, size_t tune_idx);\n",
    "  void runOpenMPVariant(VariantID vid, size_t tune_idx);\n",
    "  \n",
    "private:\n",
    "  // insert class_variables.txt\n",
    "};\n",
    "\n",
    "} // end namespace tutorial\n",
    "} // end namespace rajaperf\n",
    "\n",
    "#endif // closing endif for header file include guard\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc9ec4-2f03-47b4-a1e0-4927997f7017",
   "metadata": {},
   "source": [
    "## data setup macro\n",
    "The kernel header will define a DATA_SETUP macro which introduces the loop body variables in terms of the class variables m_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea0e36f-558c-4e5d-991f-1058f9d8800e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/data_setup.txt\n",
    "#define TUTORIAL_KERNEL_DATA_SETUP \\\n",
    "  Real_ptr mean = m_mean; \\\n",
    "  Real_ptr data = m_data; \\\n",
    "  Real_ptr symmat = m_symmat; \\\n",
    "  Real_ptr ldata = m_ldata; \\\n",
    "  const Index_type m = m_m; \\\n",
    "  const Index_type n = m_n; \\\n",
    "  Index_type i, j; \\\n",
    "  Index_type _PB_M = m_m; \\\n",
    "  Index_type _PB_N = m_n; \\\n",
    "  Real_type float_n = (Real_type)m_n;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82a8d0-5728-4fbe-a06c-7b1018c7a289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/loop_bodies.txt\n",
    "\n",
    "#define POLYBENCH_VAR_BODY0 \\\n",
    "  mean[i] = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1 \\\n",
    "  mean[i] += ldata[(j*m)+i];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2 \\\n",
    "  mean[i] /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3 \\\n",
    "  ldata[(j*m)+i] -= mean[i];\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4 \\\n",
    "  for(int kk = i; kk < m; kk++) { \\\n",
    "    symmat[(i*m)+kk] = 0.0; \\\n",
    "    for(int jj = 0; jj < n; jj++) { \\\n",
    "      symmat[(i*m)+kk] += ldata[(jj*m)+i] * ldata[(jj*m)+kk]; \\\n",
    "    } \\\n",
    "    symmat[(i*m)+kk] /= (float_n - 1.0); \\\n",
    "    symmat[(kk*m)+i] = symmat[(i*m)+kk]; \\\n",
    "  }\n",
    "  \n",
    "#define TUTORIAL_KERNEL_VIEWS_RAJA \\\n",
    "  using VIEW_1 = RAJA::View<Real_type, RAJA::Layout<1> >; \\\n",
    "  using VIEW_2 = RAJA::View<Real_type, RAJA::Layout<2> >; \\\n",
    "  VIEW_1 meanview(mean,m); \\\n",
    "  VIEW_2 dataview(ldata,n,m); \\\n",
    "  VIEW_2 symmatview(symmat,m,m);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY0_RAJA \\\n",
    "  meanview(i) = 0.0;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY1_RAJA \\\n",
    "  meanview(i) += dataview(j,i);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY2_RAJA \\\n",
    "  meanview(i) /= float_n;\n",
    "\n",
    "#define POLYBENCH_VAR_BODY3_RAJA \\\n",
    "  dataview(j,i) -= meanview(i);\n",
    "\n",
    "#define POLYBENCH_VAR_BODY4_RAJA \\\n",
    "  for(Index_type kk=i; kk < m; kk++) { \\\n",
    "    symmatview(i,kk) = 0.0; \\\n",
    "    for(Index_type jj=0; jj<n; jj++) { \\\n",
    "      symmatview(i,kk) += dataview(jj,i) * dataview(jj,kk); \\\n",
    "    } \\\n",
    "    symmatview(i,kk) /= (float_n - 1.0); \\\n",
    "    symmatview(kk,i) = symmatview(i,kk); \\\n",
    "  }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9513d-0fa9-4c61-a078-922ec8216127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/class_variables.txt\n",
    "Index_type m_m;\n",
    "Index_type m_n;\n",
    "Real_ptr m_mean;\n",
    "Real_ptr m_data;\n",
    "Real_ptr m_symmat;\n",
    "Real_ptr m_ldata;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd76d8a-c276-4b5b-9994-b7d04dca3fe9",
   "metadata": {},
   "source": [
    "## TUTORIAL_KERNEL.cpp\n",
    "In the following source we'll insert the following code fragments\n",
    "defaults.txt\n",
    "kernel_setup.txt\n",
    "checksum.txt\n",
    "kernel_teardown.txt\n",
    "```\n",
    "#include \"TUTORIAL_KERNEL.hpp\"\n",
    "\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "#include \"common/DataUtils.hpp\"\n",
    "\n",
    "\n",
    "namespace rajaperf\n",
    "{\n",
    "namespace tutorial\n",
    "{\n",
    "\n",
    "\n",
    "TUTORIAL_KERNEL::TUTORIAL_KERNEL(const RunParams& params)\n",
    "  : KernelBase(rajaperf::Tutorial_KERNEL, params)\n",
    "{\n",
    "  // insert defaults.txt \n",
    "  checksum_scale_factor = 0.001 *\n",
    "              ( static_cast<Checksum_type>(getDefaultProblemSize()) /\n",
    "                                           getActualProblemSize() );\n",
    "\n",
    "  setUsesFeature(Kernel);\n",
    "\n",
    "  setVariantDefined( Base_Seq );\n",
    "  setVariantDefined( RAJA_Seq );\n",
    "\n",
    "  setVariantDefined( Base_OpenMP );\n",
    "  setVariantDefined( RAJA_OpenMP );\n",
    "\n",
    "}\n",
    "\n",
    "TUTORIAL_KERNEL::~TUTORIAL_KERNEL()\n",
    "{\n",
    "}\n",
    "\n",
    "void TUTORIAL_KERNEL::setUp(VariantID vid, size_t RAJAPERF_UNUSED_ARG(tune_idx))\n",
    "{\n",
    "  (void) vid;\n",
    "  // insert kernel_setup.txt\n",
    "}\n",
    "\n",
    "void TUTORIAL_KERNEL::updateChecksum(VariantID vid, size_t tune_idx)\n",
    "{\n",
    "  // insert checksum.txt\n",
    "  \n",
    "}\n",
    "\n",
    "void TUTORIAL_KERNEL::tearDown(VariantID vid, size_t RAJAPERF_UNUSED_ARG(tune_idx))\n",
    "{\n",
    "  (void) vid;\n",
    "  // insert kernel_teardown.txt\n",
    "}\n",
    "\n",
    "} // end namespace tutorial\n",
    "} // end namespace rajaperf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555d7dd-bc76-4181-b15d-04ff99c1aa0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/defaults.txt\n",
    "  Index_type m_default = 1000;\n",
    "  Index_type n_default = 1000;\n",
    "  \n",
    "  setDefaultProblemSize(m_default * n_default);\n",
    "  setDefaultReps(1);\n",
    "\n",
    "  m_m = std::sqrt( getTargetProblemSize() ) +1;\n",
    "  m_n = m_m;\n",
    "\n",
    "  setActualProblemSize(m_m * m_n);\n",
    "  setItsPerRep (m_m * m_n); // not quite correct but ok for tutorial\n",
    "  setKernelsPerRep(1);\n",
    "  setBytesPerRep(sizeof(Real_type) * m_m * m_n);\n",
    "  setFLOPsPerRep(m_m * m_n); \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb313fa8-e6d2-4983-bacb-d9bd982db970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/kernel_setup.txt\n",
    "  rajaperf::detail::resetDataInitCount();\n",
    "  allocAndInitDataRandSign(m_data,m_m * m_n,vid);\n",
    "  allocAndInitDataConst(m_mean,m_m,0.0,vid);\n",
    "  allocAndInitDataConst(m_symmat,m_m*m_m,0.0,vid);\n",
    "  allocData(m_ldata,m_n*m_m,vid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ../work/checksum.txt\n",
    "  checksum[vid][tune_idx] += rajaperf::detail::calcChecksum(m_symmat,m_m * m_m, checksum_scale_factor);\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6727bca-c8e3-4c2a-a5ff-f45641020c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/kernel_teardown.txt\n",
    "  deallocData(m_data, vid);\n",
    "  deallocData(m_mean, vid);\n",
    "  deallocData(m_symmat, vid);\n",
    "  deallocData(m_ldata, vid);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b924ef7-f233-47ad-8f90-aa112f6dbc78",
   "metadata": {},
   "source": [
    "## TUTORIAL_KERNEL-seq.cpp\n",
    "In the sequential variants definition we'll insert the following code fragments\n",
    "cov_seq.txt\n",
    "cov_lambda_bodies.txt\n",
    "raja_exec_policy.txt\n",
    "raja_kernel_seq.txt\n",
    "```\n",
    "#include \"TUTORIAL_KERNEL.hpp\"\n",
    "\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "\n",
    "#include <iostream>\n",
    "\n",
    "\n",
    "namespace rajaperf\n",
    "{\n",
    "namespace tutorial\n",
    "{\n",
    "\n",
    "\n",
    "void TUTORIAL_KERNEL::runSeqVariant(VariantID vid, size_t RAJAPERF_UNUSED_ARG(tune_idx))\n",
    "{\n",
    "  const Index_type run_reps= getRunReps();\n",
    "\n",
    "  TUTORIAL_KERNEL_DATA_SETUP;\n",
    "\n",
    "  switch ( vid ) {\n",
    "\n",
    "    case Base_Seq : {\n",
    "\n",
    "      startTimer();\n",
    "      for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "       // insert cov_seq.txt\n",
    "      }\n",
    "      stopTimer();\n",
    "\n",
    "      break;\n",
    "    }\n",
    "\n",
    "#if defined(RUN_RAJA_SEQ)\n",
    "    case RAJA_Seq : {\n",
    "\n",
    "      TUTORIAL_KERNEL_VIEWS_RAJA;\n",
    "\n",
    "      // insert cov_lambda_bodies.txt\n",
    "\n",
    "      // insert raja_exec_policy.txt\n",
    "      \n",
    "      startTimer();\n",
    "      for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "        // insert raja_kernel_seq.txt\n",
    "      }\n",
    "      stopTimer();\n",
    "\n",
    "      break;\n",
    "    }\n",
    "#endif // RUN_RAJA_SEQ\n",
    "\n",
    "    default : {\n",
    "      getCout() << \"\\n  TUTORIAL_KERNEL : Unknown variant id = \" << vid << std::endl;\n",
    "    }\n",
    "\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "} // end namespace tutorial\n",
    "} // end namespace rajaperf\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7302de-b71e-4f85-aed5-f1079ae28325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/cov_seq.txt\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m_n*m_m);\n",
    "    \n",
    "  /* Determine mean of column vectors of input data matrix */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "        POLYBENCH_VAR_BODY1; \n",
    "      }\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "  }\n",
    "\n",
    "  /* Center the column vectors. */\n",
    "  for (j = 0; j < _PB_N; j++) {\n",
    "    for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  /* Calculate the m * m covariance matrix. */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "    POLYBENCH_VAR_BODY4;\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2930b7-f868-48ca-838a-e64a44cec0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/cov_lambda_bodies.txt\n",
    "    auto poly_var_base_lam0 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY0_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam1 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY1_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam2 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY2_RAJA; \n",
    "    };\n",
    "  \n",
    "    auto poly_var_base_lam3 = [=] (Index_type i, Index_type j) {\n",
    "      POLYBENCH_VAR_BODY3_RAJA; \n",
    "    };\n",
    "    \n",
    "    auto poly_var_base_lam4 = [=] (Index_type i) {\n",
    "      POLYBENCH_VAR_BODY4_RAJA;\n",
    "    };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0405cc-e045-4515-857b-0912186a218e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/raja_exec_policy.txt\n",
    "   using EXECPOL = RAJA::KernelPolicy<\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec,    // over m\n",
    "                          RAJA::statement::Lambda<0, RAJA::Segs<0> >,  // i\n",
    "                          RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                            RAJA::statement::Lambda<1, RAJA::Segs<0,1> > // i,j\n",
    "                          >,\n",
    "                          RAJA::statement::Lambda<2, RAJA::Segs<0> > // i\n",
    "                        >,\n",
    "                        RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                          RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                            RAJA::statement::Lambda<3, RAJA::Segs<0,1> > // i,j\n",
    "                          >\n",
    "                        >,\n",
    "                        RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                          RAJA::statement::Lambda<4, RAJA::Segs<0> >\n",
    "                        >\n",
    "                      >;  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00b2e1-e830-42f2-bc68-cfc8ee3913cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/raja_kernel.txt\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*m_n*m_m);\n",
    "  RAJA::kernel_param<EXECPOL>(\n",
    "          RAJA::make_tuple(RAJA::RangeSegment{0,m}, RAJA::RangeSegment{0,n}),\n",
    "          RAJA::tuple<double>{0.0}, // we're using kernel_param for the convenience of specifying iteration spaces (Segs), so we need this param tuple\n",
    "          poly_var_base_lam0,\n",
    "          poly_var_base_lam1,\n",
    "          poly_var_base_lam2,\n",
    "          poly_var_base_lam3,\n",
    "          poly_var_base_lam4\n",
    "        );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc8a42-d971-45b0-985a-f32d5cf68837",
   "metadata": {},
   "source": [
    "## TUTORIAL_KERNEL-omp.cpp\n",
    "In the openmp variants definition we'll insert the following code fragments\n",
    "cov_openmp.txt\n",
    "cov_lambda_bodies.txt\n",
    "raja_exec_policy_omp.txt\n",
    "raja_kernel.txt\n",
    "```\n",
    "#include \"TUTORIAL_KERNEL.hpp\"\n",
    "\n",
    "#include \"RAJA/RAJA.hpp\"\n",
    "\n",
    "#include <iostream>\n",
    "\n",
    "namespace rajaperf\n",
    "{\n",
    "namespace tutorial\n",
    "{\n",
    "\n",
    "\n",
    "void TUTORIAL_KERNEL::runOpenMPVariant(VariantID vid, size_t RAJAPERF_UNUSED_ARG(tune_idx))\n",
    "{\n",
    "#if defined(RAJA_ENABLE_OPENMP) && defined(RUN_OPENMP)\n",
    "\n",
    "  const Index_type run_reps= getRunReps();\n",
    "\n",
    "  TUTORIAL_KERNEL_DATA_SETUP;\n",
    "\n",
    "  switch ( vid ) {\n",
    "\n",
    "    case Base_OpenMP : {\n",
    "\n",
    "      startTimer();\n",
    "      for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "        // insert cov_openmp.txt\n",
    "      }\n",
    "      stopTimer();\n",
    "\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    case RAJA_OpenMP : {\n",
    "\n",
    "      TUTORIAL_KERNEL_VIEWS_RAJA;\n",
    "\n",
    "      // insert cov_lambda_bodies.txt\n",
    "\n",
    "      // insert raja_exec_policy_omp.txt\n",
    "    \n",
    "      startTimer();\n",
    "      for (RepIndex_type irep = 0; irep < run_reps; ++irep) {\n",
    "        // insert raja_kernel_omp.txt\n",
    "      }\n",
    "      stopTimer();\n",
    "\n",
    "      break;\n",
    "    }\n",
    "\n",
    "    default : {\n",
    "      getCout() << \"\\n  TUTORIAL_KERNEL : Unknown variant id = \" << vid << std::endl;\n",
    "    }\n",
    "\n",
    "  }\n",
    "\n",
    "#else\n",
    "  RAJA_UNUSED_VAR(vid);\n",
    "#endif\n",
    "}\n",
    "\n",
    "} // end namespace tutorial\n",
    "} // end namespace rajaperf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1b5fe-0ebe-409c-9a76-16829790426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/cov_openmp.txt\n",
    "  std::memcpy(ldata,data,sizeof(rajaperf::Real_ptr)*n*m);\n",
    "    \n",
    "  /* Determine mean of column vectors of input data matrix */\n",
    "  #pragma omp parallel for\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY0;\n",
    "      for (j = 0; j < _PB_N; j++) {\n",
    "        POLYBENCH_VAR_BODY1; \n",
    "      }\n",
    "      POLYBENCH_VAR_BODY2;\n",
    "  }\n",
    "\n",
    "  #pragma omp parallel for collapse(2)\n",
    "  /* Center the column vectors. */\n",
    "  for (j = 0; j < _PB_N; j++) {\n",
    "    for (i = 0; i < _PB_M; i++) {\n",
    "      POLYBENCH_VAR_BODY3;\n",
    "    }\n",
    "  }\n",
    "\n",
    "  #pragma omp parallel for\n",
    "  /* Calculate the m * m covariance matrix. */\n",
    "  for (i = 0; i < _PB_M; i++) {\n",
    "    POLYBENCH_VAR_BODY4;\n",
    "  }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12de6a-fcdd-4d70-b3b9-3065a9ffcf06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file ../work/raja_exec_policy_omp.txt\n",
    "  using EXECPOL = RAJA::KernelPolicy<\n",
    "                        RAJA::statement::For<0, RAJA::omp_parallel_for_exec,    // over m\n",
    "                          RAJA::statement::Lambda<0, RAJA::Segs<0> >,  // i\n",
    "                          RAJA::statement::For<1, RAJA::loop_exec,  // over n\n",
    "                            RAJA::statement::Lambda<1, RAJA::Segs<0,1> > // i,j\n",
    "                          >,\n",
    "                          RAJA::statement::Lambda<2, RAJA::Segs<0> > // i\n",
    "                        >,\n",
    "                        RAJA::statement::For<1, RAJA::omp_parallel_for_exec,  // over n\n",
    "                          RAJA::statement::For<0, RAJA::loop_exec, // over m\n",
    "                            RAJA::statement::Lambda<3, RAJA::Segs<0,1> > // i,j\n",
    "                          >\n",
    "                        >,\n",
    "                        RAJA::statement::For<0, RAJA::omp_parallel_for_exec, // over m\n",
    "                          RAJA::statement::Lambda<4, RAJA::Segs<0> >\n",
    "                        >\n",
    "                      >;  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449df0c-7bb9-4cdd-9820-6a9e6401886b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17-omp",
   "language": "C++17",
   "name": "xcpp17-omp"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
